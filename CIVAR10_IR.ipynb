{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Pre-process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from keras datasets\n",
    "(X_train, y_train), (X_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the data (normalize the input data)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the values (use Numpy command to_categorical() from np_utils)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test  = np_utils.to_categorical(y_test)\n",
    "class_num = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design and Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer of our model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3), input_shape=X_train.shape[1:], padding='same')) #pooling\n",
    "model.add(Activation('elu')) #activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dropout layer to prevent overfitting\n",
    "# Eliminating connections between the layouts\n",
    "model.add(Dropout(0.2)) #drop 0.2 * 100% of the existing connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization:\n",
    "# Ensuring that the network always creates activations with the same distribution that we desire\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling layer: help the image classifier to be more robust in terms of identifying relevant pattern\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output and eliminate some of the connections again\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densely Connected Layer\n",
    "model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Densely Connected Layer: Specifying the number of neurons in the dense layer.\n",
    "kernel_constraint is used to regularized the data as it learns (it also helps with reducing overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(class_num))\n",
    "model.add(Activation('softmax')) #softmax activation select which neurons have the highest probability as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,264,458\n",
      "Trainable params: 2,263,114\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 386s 8ms/step - loss: 1.4222 - accuracy: 0.4955 - val_loss: 0.9898 - val_accuracy: 0.6470\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 376s 8ms/step - loss: 0.9637 - accuracy: 0.6600 - val_loss: 0.8316 - val_accuracy: 0.7144\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 375s 8ms/step - loss: 0.8102 - accuracy: 0.7170 - val_loss: 0.7998 - val_accuracy: 0.7213\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.7260 - accuracy: 0.7453 - val_loss: 0.6960 - val_accuracy: 0.7548\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.6738 - accuracy: 0.7624 - val_loss: 0.6751 - val_accuracy: 0.7646\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 375s 8ms/step - loss: 0.6283 - accuracy: 0.7784 - val_loss: 0.6236 - val_accuracy: 0.7833\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 376s 8ms/step - loss: 0.5889 - accuracy: 0.7941 - val_loss: 0.6260 - val_accuracy: 0.7816\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.5560 - accuracy: 0.8040 - val_loss: 0.6882 - val_accuracy: 0.7640\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.5341 - accuracy: 0.8132 - val_loss: 0.6259 - val_accuracy: 0.7814\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.5084 - accuracy: 0.8212 - val_loss: 0.6271 - val_accuracy: 0.7869\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.4894 - accuracy: 0.8278 - val_loss: 0.5784 - val_accuracy: 0.8034\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.4699 - accuracy: 0.8352 - val_loss: 0.5937 - val_accuracy: 0.7950\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.4559 - accuracy: 0.8394 - val_loss: 0.6035 - val_accuracy: 0.7934\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.4480 - accuracy: 0.8425 - val_loss: 0.5432 - val_accuracy: 0.8127\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.4278 - accuracy: 0.8496 - val_loss: 0.6163 - val_accuracy: 0.7916\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.4225 - accuracy: 0.8518 - val_loss: 0.5635 - val_accuracy: 0.8082\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.4080 - accuracy: 0.8559 - val_loss: 0.5275 - val_accuracy: 0.8236\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 384s 8ms/step - loss: 0.4111 - accuracy: 0.8569 - val_loss: 0.5219 - val_accuracy: 0.8217\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.3971 - accuracy: 0.8597 - val_loss: 0.5899 - val_accuracy: 0.8009\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.3892 - accuracy: 0.8640 - val_loss: 0.6979 - val_accuracy: 0.7686\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.3906 - accuracy: 0.8623 - val_loss: 0.5246 - val_accuracy: 0.8259\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.3741 - accuracy: 0.8664 - val_loss: 0.5280 - val_accuracy: 0.8235\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 382s 8ms/step - loss: 0.3738 - accuracy: 0.8694 - val_loss: 0.5050 - val_accuracy: 0.8336\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 384s 8ms/step - loss: 0.3630 - accuracy: 0.8724 - val_loss: 0.5297 - val_accuracy: 0.8194\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.3606 - accuracy: 0.8731 - val_loss: 0.5090 - val_accuracy: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1931c6a2ac8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5090310754776001 / Test accuracy: 0.8305000066757202\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
